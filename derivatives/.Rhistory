# Read in the sublist_all.txt file
subs <- read.table(file.path(codedir, "sublist_all.txt"), header = FALSE, stringsAsFactors = FALSE)
# Convert subs to a vector
subs_vector <- subs$V1  # Assuming sub IDs are in the first column
# Read in the rf1_covariates_2024_09_09.csv file
data <- read.csv(file.path(codedir, "rf1_covariates_2024_09_09.csv"))
# Filter data to keep only rows with sub IDs present in the subs variable
data_filtered <- data %>% filter(sub_id_rf1_data %in% subs_vector)
# Specify model dataframes with different column combinations
data_model1 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, nbs_adult_sum, fevs_sum)
data_model2 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, mspss_sum, oafem_total)
data_model3 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, nbs_adult_sum, oafem_total)
# Put all models in a list for easy iteration
models <- list(data_model1, data_model2, data_model3)
# Define a function that processes each model
process_model <- function(data, model_number) {
# 1. Ensure NaN values are converted to NA
data_clean <- data %>%
mutate(across(everything(), ~ ifelse(is.nan(.), NA, .))) %>%  # Convert NaNs to NAs
drop_na()  # Remove rows with any NA values
# Check if any rows are left after drop_na()
if (nrow(data_clean) == 0) {
stop(paste("No data left after removing rows with missing values in model", model_number))
}
# 2. Write sub_id_rf1_data out as a separate .txt file
write.table(data_clean$sub_id_rf1_data,
file = file.path(codedir, paste0("sublist_model-", model_number, ".txt")),
row.names = FALSE, col.names = FALSE)
# 3. Mean-center all columns except for sub_id_rf1_data
data_centered <- data_clean %>%
mutate(across(-sub_id_rf1_data, scale, center = TRUE, scale = FALSE))  # Mean-center (no scaling)
# 4. Create interaction terms for all combinations of mean-centered variables
var_names <- colnames(data_centered)[-1]  # Exclude sub_id_rf1_data
# Ensure there are valid variables to work with
interaction_data <- data_centered
# Check if variables have any non-NA values before calculating interaction terms
for (i in 1:length(var_names)) {
for (j in (i + 1):length(var_names)) {
if (all(is.na(data_centered[[var_names[i]]])) || all(is.na(data_centered[[var_names[j]]]))) {
next  # Skip interaction if one of the columns is fully NA
}
# Two-way interaction
interaction_data[[paste0(var_names[i], "_x_", var_names[j])]] <-
data_centered[[var_names[i]]] * data_centered[[var_names[j]]]
for (k in (j + 1):length(var_names)) {
if (all(is.na(data_centered[[var_names[k]]]))) {
next  # Skip if the third column is fully NA
}
# Three-way interaction
interaction_data[[paste0(var_names[i], "_x_", var_names[j], "_x_", var_names[k])]] <-
data_centered[[var_names[i]]] * data_centered[[var_names[j]]] * data_centered[[var_names[k]]]
}
}
}
# 5. Write the processed data to an Excel file
write_xlsx(interaction_data, file.path(codedir, paste0("design_model-", model_number, ".xlsx")))
# Return the processed data
return(interaction_data)
}
# Iterate over all models and process them
processed_models <- list()
for (i in 1:length(models)) {
processed_models[[i]] <- process_model(models[[i]], i)
}
# processed_models now contains the interaction data for each model
# set working directory
maindir <- file.path("~/Documents/Github/rf1-sra-socdoors")
codedir <- file.path("~/Documents/Github/rf1-sra-socdoors/code")
# Load necessary libraries
library(dplyr)
library(tidyr)
library(writexl)
# Read in the sublist_all.txt file
subs <- read.table(file.path(codedir, "sublist_all.txt"), header = FALSE, stringsAsFactors = FALSE)
# Convert subs to a vector
subs_vector <- subs$V1  # Assuming sub IDs are in the first column
# Read in the rf1_covariates_2024_09_09.csv file
data <- read.csv(file.path(codedir, "rf1_covariates_2024_09_09.csv"))
# Filter data to keep only rows with sub IDs present in the subs variable
data_filtered <- data %>% filter(sub_id_rf1_data %in% subs_vector)
# Specify model dataframes with different column combinations
data_model1 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, nbs_adult_sum, fevs_sum)
data_model2 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, mspss_sum, oafem_total)
data_model3 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, nbs_adult_sum, oafem_total)
# Put all models in a list for easy iteration
models <- list(data_model1, data_model2, data_model3)
# Define a function that processes each model
process_model <- function(data, model_number) {
# 1. Ensure NaN values are converted to NA
data_clean <- data %>%
mutate(across(everything(), ~ ifelse(is.nan(.), NA, .))) %>%  # Convert NaNs to NAs
drop_na()  # Remove rows with any NA values
# Check if any rows are left after drop_na()
if (nrow(data_clean) == 0) {
stop(paste("No data left after removing rows with missing values in model", model_number))
}
# 2. Write sub_id_rf1_data out as a separate .txt file
write.table(data_clean$sub_id_rf1_data,
file = file.path(codedir, paste0("sublist_model-", model_number, ".txt")),
row.names = FALSE, col.names = FALSE)
# 3. Mean-center all columns except for sub_id_rf1_data
data_centered <- data_clean %>%
mutate(across(-sub_id_rf1_data, scale, center = TRUE, scale = FALSE))  # Mean-center (no scaling)
# 4. Create interaction terms for all combinations of mean-centered variables
var_names <- colnames(data_centered)[-1]  # Exclude sub_id_rf1_data
# Ensure there are valid variables to work with
interaction_data <- data_centered
# Check if variables have any non-NA values before calculating interaction terms
for (i in 1:length(var_names)) {
for (j in (i + 1):length(var_names)) {
if (all(is.na(data_centered[[var_names[i]]])) || all(is.na(data_centered[[var_names[j]]]))) {
next  # Skip interaction if one of the columns is fully NA
}
# Two-way interaction
interaction_data[[paste0(var_names[i], "_x_", var_names[j])]] <-
data_centered[[var_names[i]]] * data_centered[[var_names[j]]]
for (k in (j + 1):length(var_names)) {
if (all(is.na(data_centered[[var_names[k]]]))) {
next  # Skip if the third column is fully NA
}
# Three-way interaction
interaction_data[[paste0(var_names[i], "_x_", var_names[j], "_x_", var_names[k])]] <-
data_centered[[var_names[i]]] * data_centered[[var_names[j]]] * data_centered[[var_names[k]]]
}
}
}
# 5. Write the processed data to an Excel file
write_xlsx(interaction_data, file.path(codedir, paste0("design_model-", model_number, ".xlsx")))
# Return the processed data
return(interaction_data)
}
# Iterate over all models and process them
processed_models <- list()
for (i in 1:length(models)) {
processed_models[[i]] <- process_model(models[[i]], i)
}
# processed_models now contains the interaction data for each model
# set working directory
maindir <- file.path("~/Documents/Github/rf1-sra-socdoors")
codedir <- file.path("~/Documents/Github/rf1-sra-socdoors/code")
# Load necessary libraries
library(dplyr)
library(tidyr)
library(writexl)
# Read in the sublist_all.txt file
subs <- read.table(file.path(codedir, "sublist_all.txt"), header = FALSE, stringsAsFactors = FALSE)
# Convert subs to a vector
subs_vector <- subs$V1  # Assuming sub IDs are in the first column
# Read in the rf1_covariates_2024_09_09.csv file
data <- read.csv(file.path(codedir, "rf1_covariates_2024_09_09.csv"))
# Filter data to keep only rows with sub IDs present in the subs variable
data_filtered <- data %>% filter(sub_id_rf1_data %in% subs_vector)
# set working directory
maindir <- file.path("~/Documents/Github/rf1-sra-socdoors")
codedir <- file.path("~/Documents/Github/rf1-sra-socdoors/code")
c
clc
# set working directory
maindir <- file.path("~/Documents/Github/rf1-sra-socdoors")
codedir <- file.path("~/Documents/Github/rf1-sra-socdoors/code")
# Load necessary libraries
library(dplyr)
library(tidyr)
library(writexl)
# Read in the sublist_all.txt file
subs <- read.table(file.path(codedir, "sublist_all.txt"), header = FALSE, stringsAsFactors = FALSE)
# Convert subs to a vector
subs_vector <- subs$V1  # Assuming sub IDs are in the first column
# Read in the rf1_covariates_2024_09_09.csv file
data <- read.csv(file.path(codedir, "rf1_covariates_2024_09_09.csv"))
# Filter data to keep only rows with sub IDs present in the subs variable
data_filtered <- data %>% filter(sub_id_rf1_data %in% subs_vector)
# Specify model dataframes with different column combinations
data_model1 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, nbs_adult_sum, fevs_sum)
data_model2 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, mspss_sum, oafem_total)
data_model3 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, nbs_adult_sum, oafem_total)
# Put all models in a list for easy iteration
models <- list(data_model1, data_model2, data_model3)
# Define a function that processes each model
process_model <- function(data, model_number) {
# 1. Ensure NaN values are converted to NA
data_clean <- data %>%
mutate(across(everything(), ~ ifelse(is.nan(.), NA, .))) %>%  # Convert NaNs to NAs
drop_na()  # Remove rows with any NA values
# Check if any rows are left after drop_na()
if (nrow(data_clean) == 0) {
stop(paste("No data left after removing rows with missing values in model", model_number))
}
# 2. Write sub_id_rf1_data out as a separate .txt file
write.table(data_clean$sub_id_rf1_data,
file = file.path(codedir, paste0("sublist_model-", model_number, ".txt")),
row.names = FALSE, col.names = FALSE)
# 3. Mean-center all columns except for sub_id_rf1_data
data_centered <- data_clean %>%
mutate(across(-sub_id_rf1_data, scale, center = TRUE, scale = FALSE))  # Mean-center (no scaling)
# 4. Create interaction terms for all combinations of mean-centered variables
var_names <- colnames(data_centered)[-1]  # Exclude sub_id_rf1_data
# Ensure there are valid variables to work with
interaction_data <- data_centered
# Check if variables have any non-NA values before calculating interaction terms
for (i in 1:length(var_names)) {
for (j in (i + 1):length(var_names)) {
if (all(is.na(data_centered[[var_names[i]]])) || all(is.na(data_centered[[var_names[j]]]))) {
next  # Skip interaction if one of the columns is fully NA
}
# Two-way interaction
interaction_data[[paste0(var_names[i], "_x_", var_names[j])]] <-
data_centered[[var_names[i]]] * data_centered[[var_names[j]]]
for (k in (j + 1):length(var_names)) {
if (all(is.na(data_centered[[var_names[k]]]))) {
next  # Skip if the third column is fully NA
}
# Three-way interaction
interaction_data[[paste0(var_names[i], "_x_", var_names[j], "_x_", var_names[k])]] <-
data_centered[[var_names[i]]] * data_centered[[var_names[j]]] * data_centered[[var_names[k]]]
}
}
}
# 5. Write the processed data to an Excel file
write_xlsx(interaction_data, file.path(codedir, paste0("design_model-", model_number, ".xlsx")))
# Return the processed data
return(interaction_data)
}
# Iterate over all models and process them
processed_models <- list()
for (i in 1:length(models)) {
processed_models[[i]] <- process_model(models[[i]], i)
}
# processed_models now contains the interaction data for each model
maindir <- file.path("~/Documents/Github/rf1-sra-socdoors")
codedir <- file.path("~/Documents/Github/rf1-sra-socdoors/code")
# Load necessary libraries
library(dplyr)
library(tidyr)
library(writexl)
# Read in the sublist_all.txt file
subs <- read.table(file.path(codedir, "sublist_all.txt"), header = FALSE, stringsAsFactors = FALSE)
# Convert subs to a vector
subs_vector <- subs$V1  # Assuming sub IDs are in the first column
# Read in the rf1_covariates_2024_09_09.csv file
data <- read.csv(file.path(codedir, "rf1_covariates_2024_09_09.csv"))
# Filter data to keep only rows with sub IDs present in the subs variable
data_filtered <- data %>% filter(sub_id_rf1_data %in% subs_vector)
# Specify model dataframes with different column combinations
data_model2 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, nbs_adult_sum, fevs_sum)
data_model2_clean <- data_model2 %>%
mutate(across(everything(), ~ ifelse(is.nan(.), NA, .))) %>%  # Convert NaNs to NAs
drop_na()  # Remove rows with any NA values
View(data_model2_clean)
View(data_model2_clean)
# Define the path to the text file
text_file_path <- file.path("~/Documents/Github/rf1-sra-socdoors/imaging_plots/_thresh_corrp_tstat9_act.txt")
# Read in the text file assuming it's space or tab-delimited (you can change sep if it's a different delimiter)
new_data <- read.table(text_file_path, header = TRUE, stringsAsFactors = FALSE, sep = "")
# Check the structure of new_data to see if it matches data_model2_clean
str(new_data)
str(data_model2_clean)
# Assuming the new data needs to be appended as rows, and both have matching column names
# If they do not match, you might need to rename or reorder the columns
data_model2_clean <- bind_rows(data_model2_clean, new_data)
# Check the final dataframe
str(data_model2_clean)
View(data_model2_clean)
View(data_model2_clean)
# set working directory
maindir <- file.path("~/Documents/Github/rf1-sra-socdoors")
codedir <- file.path("~/Documents/Github/rf1-sra-socdoors/code")
# Load necessary libraries
library(dplyr)
library(tidyr)
library(writexl)
# Read in the sublist_all.txt file
subs <- read.table(file.path(codedir, "sublist_all.txt"), header = FALSE, stringsAsFactors = FALSE)
# Convert subs to a vector
subs_vector <- subs$V1  # Assuming sub IDs are in the first column
# Read in the rf1_covariates_2024_09_09.csv file
data <- read.csv(file.path(codedir, "rf1_covariates_2024_09_09.csv"))
# Filter data to keep only rows with sub IDs present in the subs variable
data_filtered <- data %>% filter(sub_id_rf1_data %in% subs_vector)
# Specify model dataframes with different column combinations
data_model2 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, nbs_adult_sum, fevs_sum)
data_model2_clean <- data_model2 %>%
mutate(across(everything(), ~ ifelse(is.nan(.), NA, .))) %>%  # Convert NaNs to NAs
drop_na()  # Remove rows with any NA values
# Define the path to the text file
text_file_path <- file.path("~/Documents/Github/rf1-sra-socdoors/imaging_plots/_thresh_corrp_tstat9_act.txt")
# Extract the file name without the extension to use as the column name
file_name <- tools::file_path_sans_ext(basename(text_file_path))
# Read in the text file without a header
new_data <- read.table(text_file_path, header = FALSE, stringsAsFactors = FALSE)
# Name the column after the file name
colnames(new_data) <- file_name
# Check the structure of new_data to ensure it's correct
str(new_data)
# Append new_data to data_model2_clean
data_model2_clean <- bind_cols(data_model2_clean, new_data)
# Check the final dataframe structure
str(data_model2_clean)
View(data_model2_clean)
View(data_model2_clean)
View(data_model2_clean)
View(data_model2_clean)
# Calculate the median of the nbs_adult_sum column
median_nbs_adult_sum <- median(data_model2_clean$nbs_adult_sum, na.rm = TRUE)
# Create the new column nbs_adult_sum_split based on the median split
data_model2_clean <- data_model2_clean %>%
mutate(nbs_adult_sum_split = ifelse(nbs_adult_sum <= median_nbs_adult_sum, "low", "high"))
# Check the new dataframe to see the new column
str(data_model2_clean)
View(data_model2_clean)
View(data_model2_clean)
# set working directory
maindir <- file.path("~/Documents/Github/rf1-sra-socdoors")
codedir <- file.path("~/Documents/Github/rf1-sra-socdoors/code")
# Load necessary libraries
library(dplyr)
library(tidyr)
library(writexl)
# Read in the sublist_all.txt file
subs <- read.table(file.path(codedir, "sublist_all.txt"), header = FALSE, stringsAsFactors = FALSE)
# Convert subs to a vector
subs_vector <- subs$V1  # Assuming sub IDs are in the first column
# Read in the rf1_covariates_2024_09_09.csv file
data <- read.csv(file.path(codedir, "rf1_covariates_2024_09_09.csv"))
# Filter data to keep only rows with sub IDs present in the subs variable
data_filtered <- data %>% filter(sub_id_rf1_data %in% subs_vector)
# Specify model dataframes with different column combinations
data_model2 <- data_filtered %>% dplyr::select(sub_id_rf1_data, sub_age, nbs_adult_sum, fevs_sum)
data_model2_clean <- data_model2 %>%
mutate(across(everything(), ~ ifelse(is.nan(.), NA, .))) %>%  # Convert NaNs to NAs
drop_na()  # Remove rows with any NA values
# Calculate the median of the nbs_adult_sum column
median_nbs_adult_sum <- median(data_model2_clean$nbs_adult_sum, na.rm = TRUE)
# Create the new column nbs_adult_sum_split based on the median split
data_model2_clean <- data_model2_clean %>%
mutate(nbs_adult_sum_split = ifelse(nbs_adult_sum <= median_nbs_adult_sum, "low", "high"))
# Check the new dataframe to see the new column
str(data_model2_clean)
# Define the path to the text file
text_file_path <- file.path("~/Documents/Github/rf1-sra-socdoors/imaging_plots/_thresh_corrp_tstat9_act.txt")
# Extract the file name without the extension and remove leading underscore (if any)
file_name <- sub("^_", "", tools::file_path_sans_ext(basename(text_file_path)))
# Read in the text file without a header
new_data <- read.table(text_file_path, header = FALSE, stringsAsFactors = FALSE)
# Name the column after the file name (without the leading underscore)
colnames(new_data) <- file_name
# Check the structure of new_data to ensure it's correct
str(new_data)
# Append new_data to data_model2_clean
data_model2_clean <- bind_cols(data_model2_clean, new_data)
# Check the final dataframe structure
str(data_model2_clean)
View(data_model2_clean)
View(data_model2_clean)
# Fig 2 B2: TEPS x RS x Behavioral Motivation
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=TRUE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Act (Social Win > Monetary Win)")+
stat_cor(method="pearson")
library(ggplot2)
# Fig 2 B2: TEPS x RS x Behavioral Motivation
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=TRUE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Act (Social Win > Monetary Win)")+
stat_cor(method="pearson")
# set working directory
maindir <- file.path("~/Documents/Github/rf1-sra-socdoors")
codedir <- file.path("~/Documents/Github/rf1-sra-socdoors/code")
# Load necessary libraries
library("readxl")
library("ggplot2")
library("ggpubr")
library("tidyverse")
library("reshape2")
library("ppcor")
library("dplyr")
library("ggcorrplot")
library("psych")
library("dplyr")
library("tidyr")
library("writexl")
# Fig 2 B2: TEPS x RS x Behavioral Motivation
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=TRUE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Act (Social Win > Monetary Win)")+
stat_cor(method="pearson")
scatter + scale_color_manual(values = c("black", "gray")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "gray"))
# Fig: Age X Need to Belong X Left LPFC Act (Social (win>loss) > Monetary (win>loss))
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Act (Social Win > Monetary Win)")+
stat_cor(method="pearson")
scatter + scale_color_manual(values = c("black", "gray")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "gray"))
# Fig: Age X Need to Belong X Left LPFC Act (Social (win>loss) > Monetary (win>loss))
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Act (Social Win > Monetary Win)", col="NBS")+
stat_cor(method="pearson")
scatter + scale_color_manual(values = c("black", "gray")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "gray"))
# Fig: Age X Need to Belong X Left LPFC Act (Social (win>loss) > Monetary (win>loss))
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Activation\nSocial (win>loss) > Monetary (win>loss)", col="NBS")+
stat_cor(method="pearson")
scatter + scale_color_manual(values = c("black", "gray")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "gray"))
# Fig: Age X Need to Belong X Left LPFC Act (Social (win>loss) > Monetary (win>loss))
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Activation\nSocial (win>loss) > Monetary (win>loss)", col="Need to Belong\n(NBS)")+
stat_cor(method="pearson")
scatter + scale_color_manual(values = c("black", "gray")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "gray"))
# Fig: Age X Need to Belong X Left LPFC Act (Social (win>loss) > Monetary (win>loss))
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Activation\nSocial (win>loss) > Monetary (win>loss)", col="Need to Belong\n(NBS)")+
scatter + scale_color_manual(values = c("black", "gray")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "gray"))
# Fig: Age X Need to Belong X Left LPFC Act (Social (win>loss) > Monetary (win>loss))
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Activation\nSocial (win>loss) > Monetary (win>loss)", col="Need to Belong\n(NBS)")
scatter + scale_color_manual(values = c("black", "gray")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "gray"))
# Fig: Age X Need to Belong X Left LPFC Act (Social (win>loss) > Monetary (win>loss))
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Activation\nSocial (win>loss) > Monetary (win>loss)", col="Need to Belong\n(NBS)")
+stat_cor(method="pearson")
# Fig: Age X Need to Belong X Left LPFC Act (Social (win>loss) > Monetary (win>loss))
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Activation\nSocial (win>loss) > Monetary (win>loss)", col="Need to Belong\n(NBS)")
#labs(x="Age",y="Left LPFC Activation\nSocial (win>loss) > Monetary (win>loss)", col="Need to Belong\n(NBS)")+
#stat_cor(method="pearson")
scatter + scale_color_manual(values = c("black", "gray")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "gray"))
# Fig: Age X Need to Belong X Left LPFC Act (Social (win>loss) > Monetary (win>loss))
scatter <- ggplot(data_model2_clean, aes(x=sub_age, y=thresh_corrp_tstat9_act, col=nbs_adult_sum_split))+
geom_point()+
geom_point(shape=1)+
geom_smooth(method=lm, se=FALSE, fullrange=TRUE, linetype="dashed", fill="lightgray")+
labs(x="Age",y="Left LPFC Activation\nSocial (win>loss) > Monetary (win>loss)", col="Need to Belong\n(NBS)")
#labs(x="Age",y="Left LPFC Activation\nSocial (win>loss) > Monetary (win>loss)", col="Need to Belong\n(NBS)")+
#stat_cor(method="pearson")
scatter + scale_color_manual(values = c("black", "gray")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "gray"))
# set working directory
library("here")
# load packages
library("readxl")
library("ggplot2")
library("ggpubr")
library("reshape2")
library("emmeans")
library("hrbrthemes")
library("umx")
library("interactions")
library("car")
library("dplyr")
library (tidyverse)
library(rstatix)
library(reshape)
library(datarium)
setwd("~/Documents/GitHub/istart-sharedreward/derivatives/")
maindir <- getwd()
datadir <- file.path("../derivatives/")
# import data
#here()
sharedreward <- read_excel("ppi_wholebrain_scatterplot.xls")
behavioral <- read_excel("ISTART-ALL-Combined-042122.xlsx")
postscan_ratings <- read.csv("df_psr.csv")
df_TPJ <- read_excel("df_TPJ.xlsx")
df_VS_ROI <- read_excel("VS_ROI_activation.xlsx")
df_VS_TPJ_ROI <- read_excel("VS-TPJ_ROI_connectivity.xlsx")
total <- inner_join(sharedreward, df_TPJ, by = "sub")
#srpr <- read.csv("../../istart/Shared_Reward/Behavioral_Analysis/SharedRewardPeerRatingsLongform.csv")
